{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase separation prediction\n",
        "\n",
        "This Colab notebook enables prediction of IDR transfer free energies and saturation concentrations from sequence.\n",
        "- The models have been trained on CALVADOS 2 slab simulation data.\n",
        "- Conditions are fixed to T=293 K and I=150 mM.\n",
        "\n",
        "<b>How to cite this notebook:</b>\n",
        "- [PREPRINT]\n",
        "\n",
        "Further references:\n",
        "- Use of $\\nu_\\mathrm{SVR}$: \\\\\n",
        "G. Tesei, A. I. Trolle, N. Jonsson, J. Betz, F. Pesce, K. E. Johansson, K. Lindorff-Larsen __Conformational ensembles of the human intrinsically disordered proteome__ _Nature_ 2024 626, 897–904 DOI: https://doi.org/10.1038/s41586-023-07004-5\n",
        "- CALVADOS 2 model: \\\\\n",
        "G. Tesei and K. Lindorff-Larsen __Improved predictions of phase behaviour of intrinsically disordered proteins by tuning the interaction range [version 2; peer review: 2 approved]__ _Open Research Europe_ 2023 2(94) DOI: https://doi.org/10.12688/openreseurope.14967.2\n",
        "\n",
        "Author: Sören von Bülow (soren.bulow@bio.ku.dk)"
      ],
      "metadata": {
        "id": "5_a5lMllIjX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Preliminary operations</b>\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "print('Setting up the environment...')\n",
        "# try:\n",
        "#     os.rmdir('sample_data')\n",
        "#     os.rmdir('sequence.*')\n",
        "#     os.rmdir('svr_model_nu*')\n",
        "#     os.rmdir('residues*')\n",
        "# except:\n",
        "#     pass\n",
        "\n",
        "!rm -r sample_data &> dump\n",
        "!rm sequence.* &> dump\n",
        "!rm svr_model_nu* &> dump\n",
        "!rm residues* &> dump\n",
        "!rm example* &> dump\n",
        "\n",
        "github_folder = 'https://raw.githubusercontent.com/KULL-Centre/_2024_buelow_PSpred/main/models'\n",
        "\n",
        "print(f'Downloading files from {github_folder}')\n",
        "\n",
        "os.system(f'wget {github_folder}/sequence.py')\n",
        "os.system(f'wget {github_folder}/residues.csv')\n",
        "os.system(f'wget {github_folder}/svr_model_nu.joblib')\n",
        "os.system(f'wget {github_folder}/example.fasta')\n",
        "\n",
        "!pip install 'scikit-learn==1.3' MDAnalysis biopython numba &> dump\n",
        "\n",
        "import joblib\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "import sequence\n",
        "import numpy as np\n",
        "import MDAnalysis as mda\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "ncrossval = 50\n",
        "print('Environment set up.')\n",
        "print('Loading models...')\n",
        "\n",
        "# if os.path.isfile('models_loaded'):\n",
        "  # print('Models already downloaded. Skip download.')\n",
        "# else:\n",
        "os.system(f'wget -P mlmodels {github_folder}/model_dG.joblib')#?raw=true')\n",
        "os.system(f'wget -P mlmodels {github_folder}/model_logcdil_mgml.joblib')#?raw=true')\n",
        "# !touch models_loaded\n",
        "\n",
        "residues = pd.read_csv('residues.csv').set_index('one')\n",
        "nu_file = 'svr_model_nu.joblib'\n",
        "\n",
        "features = ['mean_lambda', 'faro', 'shd', 'ncpr', 'fcr', 'scd', 'ah_ij','nu_svr']\n",
        "\n",
        "features_clean = {\n",
        "    'mean_lambda' : 'lambda',\n",
        "    'faro' : 'f(aromatics)',\n",
        "    'shd' : 'SHD',\n",
        "    'ncpr' : 'NCPR',\n",
        "    'fcr' : 'FCR',\n",
        "    'scd' : 'SCD',\n",
        "    'ah_ij' : 'LJ pairs',\n",
        "    'nu_svr' : 'nu(SVR)'\n",
        "}\n",
        "\n",
        "print('Input features are:')\n",
        "print('>>>>> '+ ', '.join([features_clean[fe] for fe in features]))\n",
        "\n",
        "def predict_single(X,model):\n",
        "    y = model.predict(X)\n",
        "    return y\n",
        "\n",
        "def predict_multimodels(X,models):\n",
        "    ys = np.zeros(len(models))\n",
        "    for idx, model in enumerate(models):\n",
        "        ys[idx] = predict_single(X,model)\n",
        "    return ys\n",
        "\n",
        "def X_from_seq(seq,feats,residues=[],charge_termini=True,nu_file=None,ah_intgrl_map=None):\n",
        "    X = []\n",
        "    seqfeats = sequence.SeqFeatures(seq,residues=residues,charge_termini=charge_termini,nu_file=nu_file,\n",
        "                                       ah_intgrl_map=ah_intgrl_map)\n",
        "    for feat in feats:\n",
        "        X.append(getattr(seqfeats,feat))\n",
        "    X = np.array(X)\n",
        "    X = np.reshape(X,(1,-1))\n",
        "    return X\n",
        "\n",
        "def makeXy(df,feats,target=None):\n",
        "    \"\"\" Make feature (X) -- target (y) pairs from dataframe \"\"\"\n",
        "    X, y, X_keys = [], [], []\n",
        "\n",
        "    for key, val in df.iterrows():\n",
        "        features = []\n",
        "\n",
        "        for feat in feats: # feats is a list of string\n",
        "            features.append(val[feat]) # features is a list of values\n",
        "\n",
        "        X.append(features)\n",
        "        X_keys.append(key)\n",
        "\n",
        "        if target is not None:\n",
        "            target_sim = val[target]\n",
        "            y.append(target_sim)\n",
        "\n",
        "    X = np.array(X)\n",
        "    if target is not None:\n",
        "        y = np.array(y)\n",
        "        return X, y, X_keys\n",
        "    else:\n",
        "        return X, X_keys\n",
        "\n",
        "def predict_df(df, model, features):\n",
        "    X_full, X_full_keys = makeXy(df, features)\n",
        "    ypred_full = model.predict(X_full)\n",
        "    ypred_full_m = np.mean(ypred_full,axis=0)\n",
        "    df.loc[X_full_keys,'dG_pred'] = ypred_full_m\n",
        "    return df\n",
        "\n",
        "class AttrSetter:\n",
        "    def __init__(self,**kwargs):\n",
        "        for key, val in kwargs.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "class Model:\n",
        "    def __init__(self,**kwargs):\n",
        "        self.mltype = kwargs.get('mltype','svr')\n",
        "        self.layers = kwargs.get('layers',(10,10))\n",
        "        self.alpha = kwargs.get('alpha',5)\n",
        "        self.C = kwargs.get('C',10)\n",
        "        self.epsilon = kwargs.get('epsilon',1e-2)\n",
        "        self.ptrain = kwargs.get('ptrain',0.8)\n",
        "        self.ncrossval = kwargs.get('ncrossval',50)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_data(X,y,X_keys,ptrain):\n",
        "        \"\"\" Split data into train and test set and return corresponding indices \"\"\"\n",
        "        nsamp = len(X)\n",
        "        if nsamp != len(y):\n",
        "            raise ValueError(\"X and y size is not equal!\")\n",
        "\n",
        "        random_idx = np.random.choice(nsamp, size=nsamp, replace=False)\n",
        "        ntrain = int(nsamp * ptrain)\n",
        "        train_idx = random_idx[:ntrain]\n",
        "        test_idx = random_idx[ntrain:]\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "        X_train_keys = [X_keys[idx] for idx in train_idx]\n",
        "        X_test_keys = [X_keys[idx] for idx in test_idx]\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, X_train_keys, X_test_keys\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_statistics(y, ypred, verbose=True):\n",
        "        # Pearson\n",
        "        fit = linregress(y, ypred)\n",
        "        rp = fit.rvalue\n",
        "\n",
        "        # Spearmanx\n",
        "        rs = spearmanr(y, ypred).statistic\n",
        "\n",
        "        # Root mean squared deviation\n",
        "        rmsd = np.sqrt(np.mean((y - ypred)**2))\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Pearson: {rp:.3f}, Spearman: {rs:.3f}, RMSD: {rmsd:.3f}')\n",
        "        return rp, rs, rmsd\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_statistics_multimodel(y, ypred, verbose=True):\n",
        "        nmodels = len(ypred)\n",
        "\n",
        "        rp = np.zeros((nmodels))\n",
        "        rs = np.zeros((nmodels))\n",
        "        rmsd = np.zeros((nmodels))\n",
        "\n",
        "        for idx, yp in enumerate(ypred):\n",
        "            rp[idx], rs[idx], rmsd[idx] = Model.calc_statistics(y, yp, verbose=verbose)\n",
        "        return rp, rs, rmsd\n",
        "\n",
        "    def predict(self,X):\n",
        "        ypred = np.zeros((self.ncrossval, len(X)))\n",
        "        for idx, crossval in enumerate(self.crossvals):\n",
        "            ypred[idx] = crossval.mlmodel.predict(X)\n",
        "        return ypred\n",
        "\n",
        "    def train(self,X,y,X_keys,**kwargs):\n",
        "        self.models = []\n",
        "        self.crossvals = []\n",
        "        verbose = kwargs.get('verbose',True)\n",
        "\n",
        "        for idx in range(self.ncrossval):\n",
        "            X_train, X_test, y_train, y_test, X_train_keys, X_test_keys = self.split_data(X,y,X_keys,self.ptrain)\n",
        "\n",
        "            if self.mltype == 'svr':\n",
        "                mlmodel = make_pipeline(StandardScaler(), SVR(C=self.C, epsilon=self.epsilon))\n",
        "            elif self.mltype == 'mlp':\n",
        "                mlmodel = make_pipeline(\n",
        "                    StandardScaler(),\n",
        "                    MLPRegressor(\n",
        "                        hidden_layer_sizes=self.layers,activation='tanh',\n",
        "                        solver='lbfgs',max_iter=10000,alpha=self.alpha),\n",
        "                )\n",
        "            mlmodel.fit(X_train, y_train)\n",
        "\n",
        "            ypred_train = mlmodel.predict(X_train)\n",
        "            ypred_test = mlmodel.predict(X_test)\n",
        "\n",
        "            rp, rs, rmsd = self.calc_statistics(y_test, ypred_test, verbose=verbose)\n",
        "\n",
        "            self.crossvals.append(AttrSetter(\n",
        "                X_train = X_train,\n",
        "                X_test = X_test,\n",
        "                y_train = y_train,\n",
        "                y_test = y_test,\n",
        "                X_train_keys = X_train_keys,\n",
        "                X_test_keys = X_test_keys,\n",
        "                mlmodel = mlmodel,\n",
        "                ypred_train = ypred_train,\n",
        "                ypred_test = ypred_test,\n",
        "                rp = rp,\n",
        "                rs = rs,\n",
        "                rmsd = rmsd\n",
        "            ))\n",
        "        self.rp_mean = np.mean([cval.rp for cval in self.crossvals])\n",
        "        self.rs_mean = np.mean([cval.rs for cval in self.crossvals])\n",
        "        self.rmsd_mean = np.mean([cval.rmsd for cval in self.crossvals])\n",
        "\n",
        "!touch calvados.py\n",
        "\n",
        "models = {}\n",
        "models['dG'] = joblib.load(f'mlmodels/model_dG.joblib')\n",
        "models['logcdil_mgml'] = joblib.load(f'mlmodels/model_logcdil_mgml.joblib')\n",
        "\n",
        "mltype = 'mlp'\n",
        "alpha = 5\n",
        "layers = (10,10)\n",
        "\n",
        "targets = ['dG','logcdil_mgml']\n",
        "targets_clean = {\n",
        "    'dG' : 'Delta G',\n",
        "    'logcdil_mgml' : 'Saturation concentration',\n",
        "}\n",
        "\n",
        "print('Models loaded.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1CsZ6Y9fywzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F7WtrIChg-F",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b>Predict single IDR sequence</font></b>\n",
        "\n",
        "try:\n",
        "    os.rmdir('sample_data')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "NAME = \"LAF1\" #@param {type:\"string\"}\n",
        "SEQUENCE = \"MESNQSNNGGSGNAALNRGGRYVPPHLRGGDGGAAAAASAGGDDRRGGAGGGGYRRGGGNSGGGGGGGYDRGYNDNRDDRDNRGGSGGYGRDRNYEDRGYNGGGGGGGNRGYNNNRGGGGGGYNRQDRGDGGSSNFSRGGYNNRDEGSDNRGSGRSYNNDRRDNGGDGLEHHHHHH\" #@param {type:\"string\"}\n",
        "CHARGE_TERMINI = True # @param {type:'boolean'}\n",
        "TEMPERATURE = \"293 K (fixed)\" # @param ['293 K (fixed)']\n",
        "IONIC_STRENGTH = \"150 uM (fixed)\" # @param ['150 uM (fixed)']\n",
        "\n",
        "seq = SEQUENCE\n",
        "if \" \" in seq:\n",
        "    seq = ''.join(seq.split())\n",
        "    print('Blank character(s) found in the provided sequence. Sequence has been corrected, but check for integrity.')\n",
        "\n",
        "print('='*80)\n",
        "print(f'NAME: {NAME}')\n",
        "print(f'SEQUENCE: {seq}')\n",
        "\n",
        "seqfeats = sequence.SeqFeatures(seq,residues=residues,charge_termini=CHARGE_TERMINI)\n",
        "X = X_from_seq(seq,features,residues=residues,charge_termini=CHARGE_TERMINI,nu_file=nu_file)\n",
        "\n",
        "for target in targets:\n",
        "  print('-'*80)\n",
        "  ys = models[target].predict(X)#,models)\n",
        "  ys_m = np.mean(ys)\n",
        "\n",
        "  if target == 'dG':\n",
        "    output = ys_m\n",
        "    unit = 'kT'\n",
        "    lower = ys_m - 1\n",
        "    upper = ys_m + 1\n",
        "  elif target == 'logcdil_mgml':\n",
        "    output = np.exp(ys_m)\n",
        "    lower = np.exp(ys_m-0.82)\n",
        "    upper = np.exp(ys_m+0.82)\n",
        "    unit = 'mg/mL'\n",
        "\n",
        "  print(f'{targets_clean[target]:25s} = {output:5.1f} {unit:6s} ({lower:.1f} -- {upper:.1f} {unit})')\n",
        "  if target == 'logcdil_mgml':\n",
        "    output_uM = output / seqfeats.mw * 1e6\n",
        "    lower_uM = lower / seqfeats.mw * 1e6\n",
        "    upper_uM = upper / seqfeats.mw * 1e6\n",
        "    print(f'{\"\":25s} = {output_uM:5.1f} {\"uM\":6s} ({lower_uM:.1f} -- {upper_uM:.1f} {\"uM\"})')\n",
        "print('='*80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Run batch prediction</b>\n",
        "\n",
        "#@markdown File name\n",
        "FASTA_FILE = \"example.fasta\" #@param {type:\"string\"}\n",
        "CHARGE_TERMINI = True # @param {type:'boolean'}\n",
        "TEMPERATURE = \"293 K (fixed)\" # @param ['293 K (fixed)']\n",
        "IONIC_STRENGTH = \"150 uM (fixed)\" # @param ['150 uM (fixed)']\n",
        "\n",
        "if not os.path.isfile(FASTA_FILE):\n",
        "  print(f'Please upload file {FASTA_FILE}')\n",
        "  uploaded = files.upload()\n",
        "  if FASTA_FILE not in uploaded.keys():\n",
        "    raise NameError(f'Could not find file {FASTA_FILE}')\n",
        "\n",
        "records = sequence.read_fasta(FASTA_FILE)\n",
        "\n",
        "print('-'*80)\n",
        "print(f'FASTA FILE: {FASTA_FILE}')\n",
        "print(f'NUMBER OF SEQUENCES: {len(records)}')\n",
        "\n",
        "#@title <b>Run batch prediction</font></b>\n",
        "\n",
        "df_records = pd.DataFrame(dtype=object)\n",
        "\n",
        "for name, record in tqdm(records.items(),total=len(records)):\n",
        "  seq = str(record.seq)\n",
        "  df_records.loc[name,'Sequence'] = seq\n",
        "  seqfeats = sequence.SeqFeatures(seq,residues=residues,\n",
        "                                  charge_termini=CHARGE_TERMINI,nu_file=nu_file)\n",
        "  for feat in features:\n",
        "    df_records.loc[name,feat] = getattr(seqfeats,feat)\n",
        "  X = X_from_seq(seq,features,residues=residues,\n",
        "                 charge_termini=CHARGE_TERMINI,nu_file=nu_file)\n",
        "  for target in targets:\n",
        "    ys = models[target].predict(X)#,models)\n",
        "    ys_m = np.mean(ys)\n",
        "    if target == 'dG':\n",
        "      df_records.loc[name,'Delta G [kT]'] = ys_m\n",
        "    if target == 'logcdil_mgml':\n",
        "      cdil_mgml = np.exp(ys_m)\n",
        "      df_records.loc[name,'Saturation concentration [mg/mL]'] = cdil_mgml\n",
        "      cdil_uM = cdil_mgml / seqfeats.mw * 1e6\n",
        "      df_records.loc[name,'Saturation concentration [uM]'] = cdil_uM\n",
        "\n",
        "df_records.index.name = 'Name'\n",
        "df_records.to_csv('df_PSprediction.csv')\n",
        "\n",
        "print('\\n')\n",
        "print('='*114)\n",
        "print(f'{\"Name\":20s} {\"Sequence\":33s} {\"Delta G\":>10s} {\"Saturation\":>16s} {\"Saturation\":>16s}')\n",
        "print(f'{\"\":20s} {\"\":33s} {\"\":>10s} {\"concentration\":>16s} {\"concentration\":>16s}')\n",
        "print(f'{\"\":20s} {\"\":33s} {\"[kT]\":>10s} {\"[mg/mL]\":>16s} {\"[uM]\":>16s}')\n",
        "\n",
        "print('='*114)\n",
        "for key, val in df_records.iterrows():\n",
        "  if len(list(val[\"Sequence\"])) > 30:\n",
        "    seqpr = f'{val[\"Sequence\"][:30]:30s}...'\n",
        "  else:\n",
        "    seqpr = f'{val[\"Sequence\"][:30]:30s}'\n",
        "  print(f'{key:20s} {seqpr:33s} {val[\"Delta G [kT]\"]:10.1f} {val[\"Saturation concentration [mg/mL]\"]:16.1f} {val[\"Saturation concentration [uM]\"]:16.1f}')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L9RekX9rtunn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Analysis</font></b>\n",
        "\n",
        "fcolor = plt.cm.summer\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(9,4))\n",
        "\n",
        "for idx, target in enumerate(['Delta G [kT]','Saturation concentration [mg/mL]']):\n",
        "  axij = ax[idx]\n",
        "  axij.hist(df_records[target],bins=20,color=fcolor(0))\n",
        "\n",
        "  axij.set_xlabel(f'{target}')\n",
        "  axij.set_ylabel('Counts')\n",
        "  axij.grid(alpha=0.3)\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "bNX8tEIW29um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-SCC7r8ltUTy"
      },
      "outputs": [],
      "source": [
        "#@title <b>Download dataframe</font></b>\n",
        "\n",
        "files.download('df_PSprediction.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}